{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "For each Featurization(BOWs, TF-IDF, W2V, AVGW2V-TFIDF) we need to split the data based on Time Based Slicing and apply RandomForest and GBDT Algo and find test accurcy.\n",
    "\n",
    "apply cross-val-score to find optimal depth and numbers of base trees for both RF and GBDT and for GBDT alone find optimal learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import gensim\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('database.sqlite') \n",
    "\n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con) \n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "# sort reviews based on ProductId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n",
    "# Remove duplicate reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                filtered_sentence.append(s)\n",
    "                if (final['Score'].values)[i] == 'positive': \n",
    "                    all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                if(final['Score'].values)[i] == 'negative':\n",
    "                    all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "            else:\n",
    "                continue \n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_in = open(\"final_string.pickle\",\"rb\")\n",
    "final_string = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'this witti littl book make son laugh loud re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138683</th>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>b'can rememb see the show when air televis yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417839</th>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "      <td>b'beetlejuic well written movi everyth about e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346055</th>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "      <td>b'twist rumplestiskin captur film star michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417838</th>\n",
       "      <td>451855</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AJH6LUC1UT1ON</td>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>946857600</td>\n",
       "      <td>FANTASTIC!</td>\n",
       "      <td>Beetlejuice is an excellent and funny movie. K...</td>\n",
       "      <td>b'beetlejuic excel and funni movi keaton hilar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId               ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL           shari zychinski   \n",
       "138683  150501  0006641040   AJ46FKXOVC7NR        Nicholas A Mesiano   \n",
       "417839  451856  B00004CXX9   AIUWLEQ1ADEG5          Elizabeth Medina   \n",
       "346055  374359  B00004CI84  A344SMIA5JECGM           Vincent P. Ross   \n",
       "417838  451855  B00004CXX9   AJH6LUC1UT1ON  The Phantom of the Opera   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "138706                     0                       0  positive  939340800   \n",
       "138683                     2                       2  positive  940809600   \n",
       "417839                     0                       0  positive  944092800   \n",
       "346055                     1                       2  positive  944438400   \n",
       "417838                     0                       0  positive  946857600   \n",
       "\n",
       "                                                  Summary  \\\n",
       "138706                          EVERY book is educational   \n",
       "138683  This whole series is great way to spend time w...   \n",
       "417839                               Entertainingl Funny!   \n",
       "346055                            A modern day fairy tale   \n",
       "417838                                         FANTASTIC!   \n",
       "\n",
       "                                                     Text  \\\n",
       "138706  this witty little book makes my son laugh at l...   \n",
       "138683  I can remember seeing the show when it aired o...   \n",
       "417839  Beetlejuice is a well written movie ..... ever...   \n",
       "346055  A twist of rumplestiskin captured on film, sta...   \n",
       "417838  Beetlejuice is an excellent and funny movie. K...   \n",
       "\n",
       "                                              CleanedText  \n",
       "138706  b'this witti littl book make son laugh loud re...  \n",
       "138683  b'can rememb see the show when air televis yea...  \n",
       "417839  b'beetlejuic well written movi everyth about e...  \n",
       "346055  b'twist rumplestiskin captur film star michael...  \n",
       "417838  b'beetlejuic excel and funni movi keaton hilar...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['CleanedText']=final_string\n",
    "final = final.sort_values(['Time'], ascending=[True])\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = final.tail(60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = final['CleanedText']\n",
    "y = final['Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW with RF and GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "# test_size=0.3 means out of 10k 3k will be test set and 7k train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(min_df=2)\n",
    "X_train = count_vect.fit_transform(X_train)\n",
    "X_test = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'max_depth': 25, 'n_estimators': 500}\n",
      "Best score is 0.9011904761904762\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "f1_scorer = make_scorer(f1_score, pos_label='positive')\n",
    "# Setup the hyperparameter grid\n",
    "depth_range = list(range(5,30))\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'n_estimators': [100, 200,500],\n",
    "                    'max_depth' : depth_range}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "rfc=RandomForestClassifier(random_state=1, class_weight='balanced')\n",
    "\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "rfc_cv = GridSearchCV(rfc, tuned_parameters, cv=3, n_jobs = -1, scoring=f1_scorer)\n",
    "\n",
    "# Fit it to the data\n",
    "rfc_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Parameters: {}\".format(rfc_cv.best_params_))\n",
    "print(\"Best score is {}\".format(rfc_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = rfc_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy 90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] learning_rate=0.1, max_depth=5, n_estimators=200 ................\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=100 ................\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.8864285714285715, total=  52.5s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.8827940861367045, total=  52.6s\n",
      "[CV] learning_rate=0.1, max_depth=6, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100, score=0.8827773412386599, total=  53.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.8857775555396814, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.8905, total= 1.1min\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=100, score=0.889222198414399, total= 1.2min\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.8975714285714286, total= 1.6min\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.8943495963997429, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=7, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200, score=0.8942932647668024, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.8973644739661453, total= 2.2min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=100, score=0.8897221627026641, total= 1.5min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=100, score=0.8906350453603828, total= 1.4min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=100, score=0.8928571428571429, total= 1.5min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.8997857142857143, total= 2.1min\n",
      "[CV] learning_rate=0.1, max_depth=8, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=6, n_estimators=200, score=0.8975641117222659, total= 2.1min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.8901507035211771, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=200, score=0.8971502035568888, total= 2.7min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=100 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.8930714285714285, total= 1.8min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=100, score=0.8899207086220444, total= 1.7min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=200, score=0.8997142857142857, total= 2.5min\n",
      "[CV] learning_rate=0.1, max_depth=9, n_estimators=200 ................\n",
      "[CV]  learning_rate=0.1, max_depth=7, n_estimators=200, score=0.8986356168297736, total= 2.5min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=100, score=0.8895793157631597, total= 2.3min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=100, score=0.8930714285714285, total= 2.2min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.8975787443754017, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.9003571428571429, total= 3.2min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=100, score=0.8902064433173799, total= 2.3min\n",
      "[CV] learning_rate=0.1, max_depth=10, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=8, n_estimators=200, score=0.8976355453960997, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.8923648310834941, total= 2.5min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=200, score=0.896793086208128, total= 3.7min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=200, score=0.8968497749839274, total= 3.7min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=9, n_estimators=200, score=0.8987857142857143, total= 3.7min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.8929285714285714, total= 2.7min\n",
      "[CV] learning_rate=0.1, max_depth=11, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100, score=0.891063647403386, total= 2.6min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=100, score=0.8899364331119206, total= 3.1min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=100, score=0.8925, total= 3.0min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.8975073209056496, total= 4.3min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.8986428571428572, total= 4.4min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200, score=0.897492678048432, total= 4.4min\n",
      "[CV] learning_rate=0.1, max_depth=12, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=100, score=0.8919922851632259, total= 2.9min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.8904363974001857, total= 3.6min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=200, score=0.8952931933433326, total= 4.8min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.8915, total= 3.5min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=200, score=0.8972069433530967, total= 5.0min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=11, n_estimators=200, score=0.8987857142857143, total= 5.1min\n",
      "[CV] learning_rate=0.1, max_depth=13, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=100, score=0.8904921780127152, total= 3.4min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=100, score=0.8888650810656382, total= 3.9min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.8960074280408542, total= 5.9min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=100, score=0.8915, total= 4.2min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.8975, total= 5.8min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=12, n_estimators=200, score=0.8966354739624259, total= 5.7min\n",
      "[CV] learning_rate=0.1, max_depth=14, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=100, score=0.8902778769912136, total= 3.9min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=100, score=0.8887222341261338, total= 4.4min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed: 17.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=200, score=0.8937218770087851, total= 6.4min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=100, score=0.8926428571428572, total= 4.6min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=200, score=0.8955639688549182, total= 6.4min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=13, n_estimators=200, score=0.8968571428571429, total= 6.6min\n",
      "[CV] learning_rate=0.1, max_depth=15, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=100, score=0.8888492035145368, total= 4.6min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=100, score=0.8885793871866295, total= 5.2min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=100, score=0.8904285714285715, total= 5.1min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=200, score=0.8937218770087851, total= 7.2min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=200, score=0.8934209586399029, total= 7.3min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=14, n_estimators=200, score=0.8982857142857142, total= 7.5min\n",
      "[CV] learning_rate=0.1, max_depth=16, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=100, score=0.887777698407029, total= 5.0min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=100, score=0.8852939075780302, total= 5.9min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=200, score=0.8955788872223412, total= 8.0min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=200, score=0.8964285714285715, total= 8.1min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=15, n_estimators=200, score=0.8922780198585614, total= 8.0min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=100, score=0.8897857142857143, total= 5.9min\n",
      "[CV] learning_rate=0.1, max_depth=17, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=100, score=0.8879205657546968, total= 5.4min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=100, score=0.8843654024712521, total= 6.3min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=200, score=0.8909207800557183, total= 8.9min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=200, score=0.8917220198557246, total= 9.2min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=16, n_estimators=200, score=0.8965, total= 9.4min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=100, score=0.8903571428571428, total= 6.5min\n",
      "[CV] learning_rate=0.1, max_depth=18, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=100, score=0.8861347239088506, total= 6.2min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=100, score=0.8852939075780302, total= 6.7min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=200, score=0.890135009643546, total= 9.5min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=200, score=0.8916505963859724, total= 9.8min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=100, score=0.8893571428571428, total= 7.0min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=17, n_estimators=200, score=0.8939285714285714, total=10.0min\n",
      "[CV] learning_rate=0.1, max_depth=19, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=100, score=0.884563183084506, total= 6.8min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=100, score=0.8850796371687737, total= 7.7min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=100, score=0.8892857142857142, total= 7.4min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=200, score=0.8899207086220444, total=10.6min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=200, score=0.8915791729162202, total=11.1min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=18, n_estimators=200, score=0.8936428571428572, total=11.2min\n",
      "[CV] learning_rate=0.1, max_depth=20, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=100, score=0.8839202800200014, total= 7.4min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.8851510606385258, total= 8.2min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=200, score=0.8890635045360383, total=11.2min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=200, score=0.8903649739304336, total=11.9min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.8867142857142857, total= 8.3min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=19, n_estimators=200, score=0.8942142857142857, total=12.1min\n",
      "[CV] learning_rate=0.1, max_depth=21, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100, score=0.882277305521823, total= 7.9min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=100, score=0.8845796728805085, total= 8.8min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=100, score=0.8870714285714286, total= 8.8min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.8896507392329119, total=13.0min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.8874205300378598, total=12.6min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200, score=0.8916428571428572, total=13.2min\n",
      "[CV] learning_rate=0.1, max_depth=22, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=100, score=0.8811343667404815, total= 8.7min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=100, score=0.8850082136990215, total= 9.5min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=100, score=0.8862142857142857, total= 9.2min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=200, score=0.8860632902350167, total=13.1min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=200, score=0.8881508463681166, total=14.2min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=21, n_estimators=200, score=0.8925, total=14.0min\n",
      "[CV] learning_rate=0.1, max_depth=23, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=100, score=0.8818487034788199, total= 9.2min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=100, score=0.8842225555317478, total=10.1min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=100, score=0.8842142857142857, total=10.0min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=200, score=0.8859204228873491, total=14.4min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=200, score=0.8902935504606814, total=15.0min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=22, n_estimators=200, score=0.8902142857142857, total=15.4min\n",
      "[CV] learning_rate=0.1, max_depth=24, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=100, score=0.8811343667404815, total= 9.8min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=100, score=0.8807228055138918, total=10.5min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=100, score=0.8856428571428572, total=10.5min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=200, score=0.8880794228983644, total=15.8min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=200, score=0.8856346881920137, total=15.6min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=23, n_estimators=200, score=0.8894285714285715, total=15.8min\n",
      "[CV] learning_rate=0.1, max_depth=25, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=100, score=0.8808486320451461, total=10.4min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=100, score=0.8823655453181916, total=11.2min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=100, score=0.8833571428571428, total=11.0min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=200, score=0.8859367188057996, total=17.0min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=200, score=0.8891428571428571, total=17.1min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=24, n_estimators=200, score=0.8849203514536753, total=16.9min\n",
      "[CV] learning_rate=0.1, max_depth=26, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=100, score=0.8795628259161369, total=11.0min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=100, score=0.8815084636811656, total=11.8min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=100, score=0.8857142857142857, total=11.9min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=200, score=0.8882222698378687, total=17.5min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=200, score=0.8839917136938352, total=17.6min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=25, n_estimators=200, score=0.8877142857142857, total=18.0min\n",
      "[CV] learning_rate=0.1, max_depth=27, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=100, score=0.8784198871347954, total=11.7min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=100, score=0.882579815727448, total=12.7min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=100, score=0.8826428571428572, total=12.8min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=200, score=0.8859367188057996, total=19.4min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=100, score=0.878562754482463, total=12.4min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=200, score=0.8875714285714286, total=19.5min\n",
      "[CV] learning_rate=0.1, max_depth=28, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=26, n_estimators=200, score=0.8835631116508322, total=19.4min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=100, score=0.8812941932719092, total=13.3min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=100, score=0.8847142857142857, total=13.7min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=200, score=0.8834202443031645, total=18.8min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=200, score=0.8859367188057996, total=20.1min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=27, n_estimators=200, score=0.8878571428571429, total=20.5min\n",
      "[CV] learning_rate=0.1, max_depth=29, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=100, score=0.8790627901993, total=13.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.8387972287693736, total= 1.1min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed: 118.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.838, total= 1.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100, score=0.8372740910065004, total= 1.0min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=100, score=0.8806513820441397, total=14.1min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.8527248053710449, total= 1.9min\n",
      "[CV] learning_rate=0.01, max_depth=5, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.8515714285714285, total= 2.0min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200, score=0.8535609686406171, total= 2.0min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=100, score=0.8830714285714286, total=13.4min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.8422142857142857, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.844725376758803, total= 1.4min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=100, score=0.8409886420458604, total= 1.3min\n",
      "[CV] learning_rate=0.01, max_depth=6, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.8562245553889007, total= 2.6min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.8547142857142858, total= 2.7min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=200, score=0.8855796014570387, total=21.2min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=100, score=0.8787056218301307, total=13.7min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=6, n_estimators=200, score=0.8565611829416387, total= 2.6min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=200, score=0.8835631116508322, total=21.3min\n",
      "[CV] learning_rate=0.01, max_depth=7, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.1, max_depth=28, n_estimators=200, score=0.8877142857142857, total=22.1min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=100, score=0.8471537747303765, total= 1.9min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=100, score=0.8442142857142857, total= 1.9min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=100, score=0.8444888920637188, total= 1.8min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=100, score=0.8485822441254196, total= 2.4min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=100, score=0.8459285714285715, total= 2.4min\n",
      "[CV] learning_rate=0.01, max_depth=8, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=200, score=0.8579387186629527, total= 3.7min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=200, score=0.858, total= 3.7min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=100, score=0.8476319737124081, total= 2.5min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=100 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=7, n_estimators=200, score=0.8597042645903279, total= 3.6min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=200, score=0.8631526319548604, total= 4.7min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=100, score=0.8489393614741804, total= 3.0min\n",
      "[CV] learning_rate=0.01, max_depth=9, n_estimators=200 ...............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=100, score=0.8482034431030788, total= 3.1min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=100, score=0.849, total= 3.3min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=200, score=0.8623571428571428, total= 4.6min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=8, n_estimators=200, score=0.8620615758268447, total= 4.4min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=200, score=0.8864285714285715, total=21.7min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=200, score=0.8852939075780302, total=22.1min\n",
      "[CV] learning_rate=0.01, max_depth=10, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=29, n_estimators=200, score=0.8823487391956568, total=21.4min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=200, score=0.8652239125776731, total= 6.0min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.8490107849439326, total= 3.9min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.8508571428571429, total= 4.0min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100, score=0.8502035859704264, total= 3.6min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=200, score=0.8653571428571428, total= 6.1min\n",
      "[CV] learning_rate=0.01, max_depth=11, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=9, n_estimators=200, score=0.864276019715694, total= 5.8min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=100, score=0.8502964073994714, total= 4.7min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=100, score=0.8512142857142857, total= 4.7min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.8662238411542033, total= 7.1min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=100, score=0.8498464176012572, total= 4.5min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.8659189942138724, total= 7.3min\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200, score=0.8672857142857143, total= 7.3min\n",
      "[CV] learning_rate=0.01, max_depth=12, n_estimators=200 ..............\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=100, score=0.8519391472037712, total= 5.3min\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=100, score=0.8510714285714286, total= 5.4min\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=100, score=0.8508464890349311, total= 5.2min\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=200, score=0.868, total= 8.5min\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=200, score=0.8667238054424684, total= 9.5min\n",
      "[CV] learning_rate=0.01, max_depth=13, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=11, n_estimators=200, score=0.8662047289092079, total= 8.7min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=100, score=0.8525105349617884, total= 6.0min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=100, score=0.8525714285714285, total= 6.3min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=100, score=0.8516322594471034, total= 5.9min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=200, score=0.8677237340189986, total=10.7min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=200, score=0.8663475962568755, total=10.2min\n",
      "[CV] learning_rate=0.01, max_depth=14, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=12, n_estimators=200, score=0.8685714285714285, total=11.0min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=100, score=0.8535818870080708, total= 7.0min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=100, score=0.8525, total= 7.1min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=100, score=0.8524894635331095, total= 6.5min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=200, score=0.8687857142857143, total=12.4min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=200, score=0.86743804013999, total=12.6min\n",
      "[CV] learning_rate=0.01, max_depth=15, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=13, n_estimators=200, score=0.8663475962568755, total=12.5min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=100, score=0.8556531676308835, total= 7.9min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=100, score=0.8541428571428571, total= 8.1min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=100, score=0.8533466676191157, total= 7.2min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=200, score=0.8677048360597186, total=13.5min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=200, score=0.8682236983072638, total=14.7min\n",
      "[CV] learning_rate=0.01, max_depth=16, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=14, n_estimators=200, score=0.8694285714285714, total=14.6min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=100, score=0.8561531319191487, total= 8.9min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=100, score=0.8552142857142857, total= 9.4min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=100, score=0.8534181012929495, total= 8.2min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=200, score=0.8686522391257767, total=15.7min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=200, score=0.8677048360597186, total=15.6min\n",
      "[CV] learning_rate=0.01, max_depth=17, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=15, n_estimators=200, score=0.87, total=15.8min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=100, score=0.857653024783944, total= 9.7min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=100, score=0.8561428571428571, total=10.2min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=100, score=0.8541324380312879, total= 9.2min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=200, score=0.8695093207628026, total=17.4min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=200, score=0.8667047646260447, total=16.8min\n",
      "[CV] learning_rate=0.01, max_depth=18, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=100, score=0.8580101421327048, total= 9.8min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=16, n_estimators=200, score=0.8703571428571428, total=18.4min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=100, score=0.8570714285714286, total=10.9min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=100, score=0.8552753768126294, total= 9.7min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=200, score=0.870580672809085, total=20.1min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=200, score=0.8707142857142857, total=20.2min\n",
      "[CV] learning_rate=0.01, max_depth=19, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=17, n_estimators=200, score=0.86791913708122, total=19.0min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=100, score=0.8577244482536962, total=10.8min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=100, score=0.8576428571428572, total=11.9min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=100, score=0.8564897492678049, total=10.8min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=200, score=0.8704378258695807, total=22.2min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=200, score=0.8717142857142857, total=21.7min\n",
      "[CV] learning_rate=0.01, max_depth=20, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=18, n_estimators=200, score=0.8687049074933924, total=20.0min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.8584386829512177, total=12.7min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.8589285714285714, total=12.7min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100, score=0.8572040860061433, total=11.4min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=200 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=200, score=0.8697950146418113, total=23.5min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=200, score=0.8687763411672262, total=21.9min\n",
      "[CV] learning_rate=0.01, max_depth=21, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=19, n_estimators=200, score=0.8722857142857143, total=24.2min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=100, score=0.8585815298907221, total=12.8min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=100, score=0.8584285714285714, total=13.9min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=100, score=0.8579898564183156, total=12.8min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.8707235197485894, total=25.8min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.8679905707550539, total=23.8min\n",
      "[CV] learning_rate=0.01, max_depth=22, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200, score=0.8725, total=26.8min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=100, score=0.859867152346261, total=14.1min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=100, score=0.8597142857142858, total=14.3min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=100, score=0.8585613258089864, total=13.5min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=200, score=0.871009213627598, total=27.7min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=200, score=0.8720714285714286, total=28.9min\n",
      "[CV] learning_rate=0.01, max_depth=23, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=21, n_estimators=200, score=0.8692049432102293, total=26.4min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=100, score=0.8586529533604742, total=15.3min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=100, score=0.8589899278519895, total=13.8min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=100, score=0.8592857142857143, total=15.4min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=200, score=0.870580672809085, total=30.5min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=200, score=0.8725714285714286, total=29.2min\n",
      "[CV] learning_rate=0.01, max_depth=24, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=22, n_estimators=200, score=0.8692763768840631, total=27.6min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=100, score=0.8588672237697307, total=15.5min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=100, score=0.860132866633331, total=14.6min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=100, score=0.8602857142857143, total=17.0min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=200, score=0.8704378258695807, total=31.5min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=200, score=0.8718571428571429, total=32.0min\n",
      "[CV] learning_rate=0.01, max_depth=25, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=100, score=0.8582244125419612, total=16.6min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=23, n_estimators=200, score=0.8692049432102293, total=30.3min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed: 274.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=100, score=0.8606428571428572, total=17.4min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=100, score=0.8600614329594971, total=15.7min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=200, score=0.8697950146418113, total=33.0min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=200, score=0.868419172798057, total=32.2min\n",
      "[CV] learning_rate=0.01, max_depth=26, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=100, score=0.8605099635740304, total=17.8min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=24, n_estimators=200, score=0.8701428571428571, total=36.8min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=100, score=0.86, total=19.1min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=100, score=0.8612043717408386, total=16.6min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=200, score=0.8700092850510678, total=35.1min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=200, score=0.8684906064718908, total=34.4min\n",
      "[CV] learning_rate=0.01, max_depth=27, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=25, n_estimators=200, score=0.8698571428571429, total=38.1min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=100, score=0.8593671880579958, total=18.7min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=100, score=0.8617044074576755, total=18.0min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=100, score=0.8610714285714286, total=20.2min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=200, score=0.8697950146418113, total=37.1min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=200, score=0.8699285714285714, total=38.7min\n",
      "[CV] learning_rate=0.01, max_depth=28, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=26, n_estimators=200, score=0.86791913708122, total=35.6min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=100, score=0.8591529176487394, total=20.5min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=100, score=0.8617142857142858, total=20.5min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=100 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=100, score=0.8607043360240018, total=18.8min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=200, score=0.868366545246768, total=39.6min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=200, score=0.8687857142857143, total=42.1min\n",
      "[CV] learning_rate=0.01, max_depth=29, n_estimators=200 ..............\n",
      "[CV]  learning_rate=0.01, max_depth=27, n_estimators=200, score=0.8691335095363955, total=37.0min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=100, score=0.8586529533604742, total=19.4min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=100, score=0.8607043360240018, total=18.1min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=100, score=0.8620714285714286, total=21.7min\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=200, score=0.8673666166702378, total=40.5min\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=200, score=0.8694285714285714, total=39.2min\n",
      "[CV]  learning_rate=0.01, max_depth=28, n_estimators=200, score=0.8678477034073863, total=37.2min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=200, score=0.866080994214699, total=36.0min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=200, score=0.8694285714285714, total=34.6min\n",
      "[CV]  learning_rate=0.01, max_depth=29, n_estimators=200, score=0.8667761982998785, total=29.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 370.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200}\n",
      "Best score is 0.8985238095238095\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Setup the hyperparameter grid\n",
    "depth_range = list(range(5,30))\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = {'learning_rate': [0.1, 0.01],\n",
    "'max_depth' : depth_range,\n",
    "'n_estimators': [100, 200]}\n",
    "# Instantiate a random forest classifier: gbdt\n",
    "gbdt=GradientBoostingClassifier(random_state=1)\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "gbdt_cv = GridSearchCV(gbdt, tuned_parameters, cv=3, n_jobs=-1, verbose=5)\n",
    "# Fit it to the data\n",
    "gbdt_cv.fit(X_train, y_train)\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Parameters: {}\".format(gbdt_cv.best_params_))\n",
    "print(\"Best score is {}\".format(gbdt_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = gbdt_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy 90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF with RF and GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "# test_size=0.3 means out of 10k 3k will be test set and 7k train set\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=50)\n",
    "final_tf_idf_train = tf_idf_vect.fit_transform(X_train_tfidf)\n",
    "final_tf_idf_test = tf_idf_vect.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dtc = RandomForestClassifier(max_depth=50, n_estimators=500, random_state=1).fit(final_tf_idf_train, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(final_tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_tfidf, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_tfidf, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdtc = GradientBoostingClassifier(max_depth=8, learning_rate=0.1, random_state=1, n_estimators=200).fit(final_tf_idf_train, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbdtc.predict(final_tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_tfidf, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_tfidf, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AvgW2V with RF and GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "# test_size=0.3 means out of 10k 3k will be test set and 7k train set\n",
    "X_train_avgw2v, X_test_avgw2v, y_train_avgw2v, y_test_avgw2v = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_train_avgw2v.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent.decode('utf-8'))\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhisek1651990/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    \n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent_test=[]\n",
    "for sent in X_test_avgw2v.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent.decode('utf-8'))\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    \n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)\n",
    "print(len(sent_vectors_test))\n",
    "print(len(sent_vectors_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(sent_vectors)\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "df_test = pd.DataFrame(sent_vectors_test)\n",
    "df_test = df_test.fillna(df_test.mean())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# prepare the scaler with train data\n",
    "scaler = StandardScaler(with_mean=False).fit(df_train)\n",
    "# transform both train and test data\n",
    "standardized_data_train_avgw2v = scaler.transform(df_train)\n",
    "standardized_data_test_avgw2v = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=50, random_state=1, n_estimators=500).fit(standardized_data_train_avgw2v, y_train_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(standardized_data_test_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_avgw2v, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noBARLwWFiHj9H9gXvNNjCxAAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_avgw2v, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdtc = GradientBoostingClassifier(max_depth=8, learning_rate=0.1, random_state=1, n_estimators=200).fit(standardized_data_train_avgw2v, y_train_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbdtc.predict(standardized_data_test_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_avgw2v, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nChEJ+n+Jmw94vhYIxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_avgw2v, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF-W2V RF and GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split arrays or matrices into random train and test subsets\n",
    "# test_size=0.3 means out of 10k 3k will be test set and 7k train set\n",
    "X_train_avgw2vtfidf, X_test_avgw2vtfidf, y_train_avgw2vtfidf, y_test_avgw2vtfidf = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_train_avgw2vtfidf.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent.decode('utf-8'))\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your own Word2Vec model using your own text corpus\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent_test=[]\n",
    "for sent in X_test_avgw2vtfidf.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent.decode('utf-8'))\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), stop_words='english', min_df=2)\n",
    "final_tf_idf_train = tf_idf_vect.fit_transform(X_train_avgw2vtfidf)\n",
    "final_tf_idf_test = tf_idf_vect.transform(X_test_avgw2vtfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate TF-IDF weighted Word2Vec for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tf_idf_vect.get_feature_names(), list(tf_idf_vect.idf_)))\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent: # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            try:\n",
    "                vec = w2v_model.wv[word]\n",
    "    #             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "                # to reduce the computation we are \n",
    "                # dictionary[word] = idf value of word in whole courpus\n",
    "                # sent.count(word) = tf valeus of word in this review\n",
    "                tf_idf = dictionary[word]*sent.count(word)\n",
    "                sent_vec += (vec * tf_idf)\n",
    "                weight_sum += tf_idf\n",
    "            except:\n",
    "                pass\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate TF-IDF weighted Word2Vec for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(tf_idf_vect.get_feature_names(), list(tf_idf_vect.idf_)))\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "tfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent_test: # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            try:\n",
    "                vec = w2v_model.wv[word]\n",
    "    #             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "                # to reduce the computation we are \n",
    "                # dictionary[word] = idf value of word in whole courpus\n",
    "                # sent.count(word) = tf valeus of word in this review\n",
    "                tf_idf = dictionary[word]*sent.count(word)\n",
    "                sent_vec += (vec * tf_idf)\n",
    "                weight_sum += tf_idf\n",
    "            except:\n",
    "                pass\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_test.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do standadization for train and test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(tfidf_sent_vectors)\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "df_test = pd.DataFrame(tfidf_sent_vectors_test)\n",
    "df_test = df_test.fillna(df_test.mean())\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# prepare the scaler with train data\n",
    "scaler = StandardScaler(with_mean=False).fit(df_train)\n",
    "# transform both train and test data\n",
    "standardized_data_tf_idfw2v_train = scaler.transform(df_train)\n",
    "standardized_data_tf_idfw2v_test = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=50, random_state=1, n_estimators=500).fit(standardized_data_tf_idfw2v_train, y_train_avgw2vtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(standardized_data_tf_idfw2v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 86%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_avgw2vtfidf, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_avgw2vtfidf, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdtc = GradientBoostingClassifier(max_depth=8, learning_rate=0.1, random_state=1, n_estimators=200).fit(standardized_data_tf_idfw2v_train, y_train_avgw2vtfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbdtc.predict(standardized_data_tf_idfw2v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****Test accuracy is 87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test_avgw2vtfidf, y_pred, normalize=True) * float(100)\n",
    "print('\\n****Test accuracy is %d%%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'predicted label')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAEKCAYAAADqyxvJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfX8kcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "mat = confusion_matrix(y_test_avgw2vtfidf, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurization With Random Forest:\n",
      "+----------------+------------+\n",
      "|     Model      | test error |\n",
      "+----------------+------------+\n",
      "|     BOW-RF     |    10%     |\n",
      "|    TFIDF-RF    |    13%     |\n",
      "|   AVGW2V-RF    |    13%     |\n",
      "| TFIDFAVGW2V-RF |    14%     |\n",
      "+----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Model\", \"test error\"]\n",
    "x.add_row([\"BOW-RF\", \"10%\"])\n",
    "x.add_row([\"TFIDF-RF\",  \"13%\"])\n",
    "x.add_row([\"AVGW2V-RF\",  \"13%\"])\n",
    "x.add_row([\"TFIDFAVGW2V-RF\", \"14%\"])\n",
    "print(\"Featurization With Random Forest:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurization With Gradient Boosting DT:\n",
      "+------------------+------------+\n",
      "|      Model       | test error |\n",
      "+------------------+------------+\n",
      "|     BOW-GBDT     |    10%     |\n",
      "|    TFIDF-GBDT    |    10%     |\n",
      "|   AVGW2V-GBDT    |    12%     |\n",
      "| TFIDFAVGW2V-GBDT |    13%     |\n",
      "+------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Model\", \"test error\"]\n",
    "x.add_row([\"BOW-GBDT\", \"10%\"])\n",
    "x.add_row([\"TFIDF-GBDT\",  \"10%\"])\n",
    "x.add_row([\"AVGW2V-GBDT\",  \"12%\"])\n",
    "x.add_row([\"TFIDFAVGW2V-GBDT\", \"13%\"])\n",
    "print(\"Featurization With Gradient Boosting DT:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
